name: Grant ArgoCD Access

on:
  workflow_dispatch:

env:
  AWS_REGION: us-west-2

permissions:
  id-token: write
  contents: read

jobs:
  grant_access:
    name: Grant ArgoCD Access
    runs-on: ubuntu-latest
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Update kubeconfig
        run: |
          CLUSTER_NAME=$(aws eks list-clusters --query "clusters[?contains(@, 'pet-hospital')]" --output text)
          aws eks update-kubeconfig --name $CLUSTER_NAME --region ${{ env.AWS_REGION }}

      - name: Add user to aws-auth ConfigMap
        run: |
          # Get AWS account ID dynamically
          AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          
          kubectl patch configmap aws-auth -n kube-system --type=merge -p '{"data":{"mapRoles":"- rolearn: arn:aws:sts::'"${AWS_ACCOUNT_ID}"':assumed-role/admin/anandsjo-Isengard\n  username: admin\n  groups:\n    - system:masters\n"}}'

      - name: Fix ArgoCD configuration
        run: |
          # Delete any crashing pods first
          CRASHING_PODS=$(kubectl get pods -n argocd -l app.kubernetes.io/name=argocd-server --field-selector status.phase!=Running -o name)
          if [ -n "$CRASHING_PODS" ]; then
            echo "Found crashing ArgoCD server pods, deleting them:"
            echo "$CRASHING_PODS"
            echo "$CRASHING_PODS" | xargs kubectl delete -n argocd
          fi
          
          # Create required ConfigMaps
          cat > argocd-cm.yaml << 'EOF'
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: argocd-cm
            namespace: argocd
            labels:
              app.kubernetes.io/name: argocd-cm
              app.kubernetes.io/part-of: argocd
          data:
            url: http://argocd-server
            application.instanceLabelKey: argocd.argoproj.io/instance
          EOF
          kubectl apply -f argocd-cm.yaml
          
          # Verify the ConfigMap was created
          echo "Verifying argocd-cm ConfigMap:"
          kubectl get configmap argocd-cm -n argocd
          
          # Configure ArgoCD server for HTTP access
          cat > argocd-cmd-params.yaml << 'EOF'
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: argocd-cmd-params-cm
            namespace: argocd
            labels:
              app.kubernetes.io/name: argocd-cmd-params-cm
              app.kubernetes.io/part-of: argocd
          data:
            server.insecure: "true"
          EOF
          kubectl apply -f argocd-cmd-params.yaml
          
          # Verify the ConfigMap was created
          echo "Verifying argocd-cmd-params-cm ConfigMap:"
          kubectl get configmap argocd-cmd-params-cm -n argocd
          
          # Restart ArgoCD server
          echo "Restarting ArgoCD server..."
          kubectl rollout restart deployment argocd-server -n argocd
          
          # Wait for the deployment to restart
          echo "Waiting for ArgoCD server to restart..."
          kubectl rollout status deployment argocd-server -n argocd --timeout=120s || true
          
          # Wait for pods to stabilize
          echo "Waiting for pods to stabilize..."
          sleep 30
          
          # Check ArgoCD server status
          echo "Current ArgoCD server pods:"
          kubectl get pods -n argocd -l app.kubernetes.io/name=argocd-server

      - name: Create LoadBalancer for ArgoCD
        run: |
          cat > argocd-lb.yaml << 'EOF'
          apiVersion: v1
          kind: Service
          metadata:
            name: argocd-server-lb
            namespace: argocd
            annotations:
              service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
          spec:
            ports:
            - port: 80
              targetPort: 8080
            selector:
              app.kubernetes.io/name: argocd-server
            type: LoadBalancer
          EOF
          kubectl apply -f argocd-lb.yaml
          sleep 60
          
          # Get LoadBalancer URL
          LB_URL=$(kubectl get svc argocd-server-lb -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          if [ -n "$LB_URL" ]; then
            echo "ArgoCD URL: http://${LB_URL}"
            
            # Update the argocd-cm with the LoadBalancer URL
            kubectl patch configmap argocd-cm -n argocd --type=merge -p "{\"data\":{\"url\":\"http://${LB_URL}\"}}"
          fi

      - name: Create port-forward script
        run: |
          cat > argocd-port-forward.sh << 'EOF'
          #!/bin/bash
          aws eks update-kubeconfig --name pet-hospital-eks-cluster --region us-west-2
          PASSWORD=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d)
          echo "ArgoCD credentials: admin / $PASSWORD"
          kubectl port-forward svc/argocd-server -n argocd 8080:80
          EOF
          chmod +x argocd-port-forward.sh

      - name: Display access information
        run: |
          echo "===== ArgoCD Access Information ====="
          PASSWORD=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d)
          echo "Username: admin"
          echo "Password: $PASSWORD"
          
          LB_URL=$(kubectl get svc argocd-server-lb -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          if [ -n "$LB_URL" ]; then
            echo "LoadBalancer URL: http://${LB_URL}"
          fi
          
          echo "Local access: Run ./argocd-port-forward.sh"
          echo "====================================="
