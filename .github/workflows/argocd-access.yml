name: Grant ArgoCD Access

on:
  workflow_dispatch:

env:
  AWS_REGION: us-west-2

permissions:
  id-token: write
  contents: read

jobs:
  grant_access:
    name: Grant ArgoCD Access
    runs-on: ubuntu-latest
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Update kubeconfig
        run: |
          # Get cluster name
          CLUSTER_NAME=$(aws eks list-clusters --query "clusters[?contains(@, 'pet-hospital')]" --output text)
          echo "Using cluster: $CLUSTER_NAME"
          aws eks update-kubeconfig --name $CLUSTER_NAME --region ${{ env.AWS_REGION }}

      - name: Update aws-auth ConfigMap
        run: |
          echo "Updating aws-auth ConfigMap to grant user access to the cluster..."
          
          # Get the current aws-auth ConfigMap
          kubectl get configmap aws-auth -n kube-system -o yaml > aws-auth.yaml
          
          # Check if the user is already in the ConfigMap
          if ! grep -q "arn:aws:sts::622037664315:assumed-role/admin/anandsjo-Isengard" aws-auth.yaml; then
            # Add the user to the mapRoles section
            if grep -q "mapRoles:" aws-auth.yaml; then
              # mapRoles section exists, append to it
              sed -i '/mapRoles:/a \    - rolearn: arn:aws:sts::622037664315:assumed-role/admin/anandsjo-Isengard\n      username: admin\n      groups:\n        - system:masters' aws-auth.yaml
            else
              # mapRoles section doesn't exist, create it
              sed -i '/data:/a \  mapRoles: |\n    - rolearn: arn:aws:sts::622037664315:assumed-role/admin/anandsjo-Isengard\n      username: admin\n      groups:\n        - system:masters' aws-auth.yaml
            fi
            
            # Apply the updated ConfigMap
            kubectl apply -f aws-auth.yaml
            echo "User added to aws-auth ConfigMap"
          else
            echo "User already exists in aws-auth ConfigMap"
          fi

      - name: Configure ArgoCD Server
        run: |
          echo "Configuring ArgoCD server for ingress access..."
          
          # Create a patch file for more extensive configuration
          cat > argocd-cm-patch.yaml << EOF
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: argocd-cmd-params-cm
            namespace: argocd
          data:
            server.rootpath: "/"
            server.insecure: "true"
            server.enable.gzip: "true"
            server.basehref: "/"
            server.log.format: "text"
            server.log.level: "debug"
          EOF
          
          # Apply the patch
          kubectl apply -f argocd-cm-patch.yaml
          
          # Restart ArgoCD server to apply changes
          kubectl rollout restart deployment argocd-server -n argocd
          
          # Wait for ArgoCD server to be ready
          echo "Waiting for ArgoCD server to restart..."
          kubectl rollout status deployment argocd-server -n argocd --timeout=120s

      - name: Create ArgoCD Ingress
        run: |
          echo "Creating ArgoCD Ingress for external access..."
          
          # Create an Ingress resource for ArgoCD
          cat > argocd-ingress.yaml << EOF
          apiVersion: networking.k8s.io/v1
          kind: Ingress
          metadata:
            name: argocd-server-ingress
            namespace: argocd
            annotations:
              kubernetes.io/ingress.class: alb
              alb.ingress.kubernetes.io/scheme: internet-facing
              alb.ingress.kubernetes.io/target-type: ip
              alb.ingress.kubernetes.io/backend-protocol: HTTPS
              alb.ingress.kubernetes.io/listen-ports: '[{"HTTP":80}]'
              alb.ingress.kubernetes.io/healthcheck-path: /healthz
              alb.ingress.kubernetes.io/healthcheck-protocol: HTTPS
              alb.ingress.kubernetes.io/success-codes: '200'
              alb.ingress.kubernetes.io/target-group-attributes: stickiness.enabled=true,stickiness.lb_cookie.duration_seconds=3600
              alb.ingress.kubernetes.io/load-balancer-attributes: idle_timeout.timeout_seconds=600
              alb.ingress.kubernetes.io/group.name: argocd
              alb.ingress.kubernetes.io/ssl-policy: ELBSecurityPolicy-TLS-1-2-2017-01
          spec:
            rules:
              - http:
                  paths:
                    - path: /
                      pathType: Prefix
                      backend:
                        service:
                          name: argocd-server
                          port:
                            number: 443
          EOF
          
          # Apply the Ingress resource
          kubectl apply -f argocd-ingress.yaml
          
          # Wait for the Ingress to be created
          echo "Waiting for ArgoCD Ingress to be created..."
          sleep 30

      - name: Configure ALB Security Group
        run: |
          echo "Configuring ALB security group..."
          
          # Get the ALB ARN
          ALB_ARN=$(aws elbv2 describe-load-balancers --query "LoadBalancers[?contains(DNSName, 'k8s-argocd')].LoadBalancerArn" --output text)
          
          if [ -n "$ALB_ARN" ]; then
            # Get the security group ID
            SG_ID=$(aws elbv2 describe-load-balancers --load-balancer-arns $ALB_ARN --query "LoadBalancers[0].SecurityGroups[0]" --output text)
            
            echo "ALB Security Group ID: $SG_ID"
            
            # Ensure the security group allows inbound traffic on port 80
            aws ec2 authorize-security-group-ingress \
              --group-id $SG_ID \
              --protocol tcp \
              --port 80 \
              --cidr 0.0.0.0/0 || echo "Inbound rule already exists"
          else
            echo "ALB not found or still being created"
          fi
          
          # Wait a bit more for the ALB to be fully configured
          echo "Waiting for ALB to be fully configured..."
          sleep 30

      - name: Debug ArgoCD Setup
        run: |
          echo "Debugging ArgoCD setup..."
          
          # Check ArgoCD pods
          echo "ArgoCD pods:"
          kubectl get pods -n argocd
          
          # Check ArgoCD services
          echo "ArgoCD services:"
          kubectl get svc -n argocd
          
          # Check ArgoCD ingress
          echo "ArgoCD ingress:"
          kubectl get ingress -n argocd -o yaml
          
          # Check ALB target groups
          echo "ALB target groups:"
          aws elbv2 describe-target-groups --query "TargetGroups[?contains(TargetGroupName, 'argocd')]"
          
          # Check ALB target health
          TG_ARN=$(aws elbv2 describe-target-groups --query "TargetGroups[?contains(TargetGroupName, 'argocd')].TargetGroupArn" --output text)
          if [ -n "$TG_ARN" ]; then
            echo "Target health:"
            aws elbv2 describe-target-health --target-group-arn $TG_ARN
          fi
          
          # Get the Ingress URL
          ARGOCD_URL=$(kubectl get ingress argocd-server-ingress -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          
          if [ -n "$ARGOCD_URL" ]; then
            echo "ArgoCD is accessible at: http://${ARGOCD_URL}"
            echo "ARGOCD_URL=http://${ARGOCD_URL}" >> $GITHUB_ENV
            
            # Get ArgoCD admin password
            ARGOCD_PASSWORD=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d)
            echo "ArgoCD admin password: $ARGOCD_PASSWORD"
          else
            echo "ArgoCD Ingress URL not available yet. Check the AWS Console for the ALB URL."
          fi

      - name: Create Direct Service Access
        run: |
          echo "Creating a direct service access as a backup method..."
          
          # Create a LoadBalancer service for direct access
          cat > argocd-lb-service.yaml << EOF
          apiVersion: v1
          kind: Service
          metadata:
            name: argocd-server-lb
            namespace: argocd
          spec:
            ports:
            - name: http
              port: 80
              protocol: TCP
              targetPort: 8080
            selector:
              app.kubernetes.io/name: argocd-server
            type: LoadBalancer
          EOF
          
          # Apply the service
          kubectl apply -f argocd-lb-service.yaml
          
          # Wait for the service to get an external IP
          echo "Waiting for LoadBalancer service to get an external IP..."
          sleep 30
          
          # Get the LoadBalancer URL
          LB_URL=$(kubectl get svc argocd-server-lb -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          
          if [ -n "$LB_URL" ]; then
            echo "ArgoCD is also accessible directly at: http://${LB_URL}"
            echo "ARGOCD_LB_URL=http://${LB_URL}" >> $GITHUB_ENV
          else
            echo "Direct LoadBalancer URL not available yet."
          fi
