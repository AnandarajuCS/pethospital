name: Grant ArgoCD Access

on:
  workflow_dispatch:

env:
  AWS_REGION: us-west-2

permissions:
  id-token: write
  contents: read

jobs:
  grant_access:
    name: Grant ArgoCD Access
    runs-on: ubuntu-latest
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Update kubeconfig
        run: |
          # Get cluster name
          CLUSTER_NAME=$(aws eks list-clusters --query "clusters[?contains(@, 'pet-hospital')]" --output text)
          echo "Using cluster: $CLUSTER_NAME"
          aws eks update-kubeconfig --name $CLUSTER_NAME --region ${{ env.AWS_REGION }}

      - name: Update aws-auth ConfigMap
        run: |
          echo "Updating aws-auth ConfigMap to grant user access to the cluster..."
          
          # Get the current aws-auth ConfigMap
          kubectl get configmap aws-auth -n kube-system -o yaml > aws-auth.yaml
          
          # Check if the user is already in the ConfigMap
          if ! grep -q "arn:aws:sts::622037664315:assumed-role/admin/anandsjo-Isengard" aws-auth.yaml; then
            # Add the user to the mapRoles section
            if grep -q "mapRoles:" aws-auth.yaml; then
              # mapRoles section exists, append to it
              sed -i '/mapRoles:/a \    - rolearn: arn:aws:sts::622037664315:assumed-role/admin/anandsjo-Isengard\n      username: admin\n      groups:\n        - system:masters' aws-auth.yaml
            else
              # mapRoles section doesn't exist, create it
              sed -i '/data:/a \  mapRoles: |\n    - rolearn: arn:aws:sts::622037664315:assumed-role/admin/anandsjo-Isengard\n      username: admin\n      groups:\n        - system:masters' aws-auth.yaml
            fi
            
            # Apply the updated ConfigMap
            kubectl apply -f aws-auth.yaml
            echo "User added to aws-auth ConfigMap"
          else
            echo "User already exists in aws-auth ConfigMap"
          fi

      - name: Skip ArgoCD Configuration
        run: |
          echo "Skipping ArgoCD server configuration to avoid restart issues..."
          echo "Will proceed directly to creating access methods."

      - name: Create Direct LoadBalancer Service
        run: |
          echo "Creating a direct LoadBalancer service for ArgoCD..."
          
          # Delete existing service if it exists
          kubectl delete service argocd-server-lb -n argocd --ignore-not-found
          
          # Create a simple LoadBalancer service
          cat > argocd-lb-service.yaml << EOF
          apiVersion: v1
          kind: Service
          metadata:
            name: argocd-server-lb
            namespace: argocd
          spec:
            ports:
            - name: http
              port: 80
              protocol: TCP
              targetPort: 8080
            selector:
              app.kubernetes.io/name: argocd-server
            type: LoadBalancer
          EOF
          
          # Apply the service
          kubectl apply -f argocd-lb-service.yaml
          
          # Wait for the service to get an external IP
          echo "Waiting for LoadBalancer service to get an external IP..."
          sleep 60
          
          # Get the LoadBalancer URL
          LB_URL=$(kubectl get svc argocd-server-lb -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          
          if [ -n "$LB_URL" ]; then
            echo "ArgoCD is accessible directly at: http://${LB_URL}"
            echo "ARGOCD_LB_URL=http://${LB_URL}" >> $GITHUB_ENV
            
            # Get ArgoCD admin password
            ARGOCD_PASSWORD=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d)
            echo "ArgoCD admin password: $ARGOCD_PASSWORD"
          else
            echo "Direct LoadBalancer URL not available yet."
          fi

      - name: Configure Security Groups
        run: |
          echo "Configuring security groups for worker nodes..."
          
          # Get the NLB name
          LB_URL=$(kubectl get svc argocd-server-lb -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          
          if [ -n "$LB_URL" ]; then
            # Get the cluster name
            CLUSTER_NAME=$(aws eks list-clusters --query "clusters[?contains(@, 'pet-hospital')]" --output text)
            
            # Get the security group IDs for the worker nodes
            NODE_SECURITY_GROUPS=$(aws ec2 describe-instances --filters "Name=tag:kubernetes.io/cluster/$CLUSTER_NAME,Values=owned" --query "Reservations[*].Instances[*].SecurityGroups[*].GroupId" --output text)
            
            echo "Node security groups: $NODE_SECURITY_GROUPS"
            
            # For each security group, ensure it allows traffic on port 8080
            for SG_ID in $NODE_SECURITY_GROUPS; do
              echo "Updating security group $SG_ID to allow traffic on port 8080..."
              
              # Allow inbound traffic on port 8080 from anywhere
              aws ec2 authorize-security-group-ingress \
                --group-id $SG_ID \
                --protocol tcp \
                --port 8080 \
                --cidr 0.0.0.0/0 || echo "Inbound rule already exists or failed to add"
            done
          else
            echo "LoadBalancer not found or still being created"
          fi

      - name: Create Port-Forward Script
        run: |
          echo "Creating a port-forward script for local access..."
          
          cat > argocd-port-forward.sh << 'EOF'
          #!/bin/bash
          
          # Update kubeconfig
          aws eks update-kubeconfig --name pet-hospital-eks-cluster --region us-west-2
          
          # Port-forward ArgoCD server
          echo "Starting port-forward to ArgoCD server..."
          kubectl port-forward svc/argocd-server -n argocd 8080:443
          
          # Instructions will be printed before port-forwarding starts
          echo "Access ArgoCD at: https://localhost:8080"
          echo "Username: admin"
          echo "Password: $(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d)"
          EOF
          
          chmod +x argocd-port-forward.sh
          echo "Created port-forward script: argocd-port-forward.sh"
          echo "You can use this script locally to access ArgoCD via port-forwarding"

      - name: Debug ArgoCD Setup
        run: |
          echo "Debugging ArgoCD setup..."
          
          # Check ArgoCD pods
          echo "ArgoCD pods:"
          kubectl get pods -n argocd
          
          # Check ArgoCD services
          echo "ArgoCD services:"
          kubectl get svc -n argocd
          
          # Check direct LoadBalancer service
          echo "Direct LoadBalancer service details:"
          kubectl get svc argocd-server-lb -n argocd -o yaml
          
          # Get ArgoCD admin password
          ARGOCD_PASSWORD=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d)
          echo "ArgoCD admin password: $ARGOCD_PASSWORD"
          
          # Get the LoadBalancer URL
          LB_URL=$(kubectl get svc argocd-server-lb -n argocd -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          
          if [ -n "$LB_URL" ]; then
            echo "ArgoCD is accessible directly at: http://${LB_URL}"
            echo "ARGOCD_LB_URL=http://${LB_URL}" >> $GITHUB_ENV
          else
            echo "Direct LoadBalancer URL not available yet."
          fi
          
          echo "Access ArgoCD using username: admin and the password shown above."
          echo "You can also use port-forwarding with the provided script."
